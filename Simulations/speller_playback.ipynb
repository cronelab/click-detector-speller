{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47c4ca36-636d-4f5a-b33c-1768a66ae54d",
   "metadata": {},
   "source": [
    "# SCRIPT DESCRIPTION"
   ]
  },
  {
   "cell_type": "raw",
   "id": "abfaf978-3670-4edc-b8ff-4e3a767044c6",
   "metadata": {},
   "source": [
    "This script simulates real-time click detection during a previously recorded block of data in which attempted grasping\n",
    "was performed. Specifically, the experimenter uploads a block of data during which the particpant attempted grasps and\n",
    "a linear classification model (with other model parameters such as calibration statistics) trained on blocks of data \n",
    "from similar grasp-based tasks. The data of the block on which the model will be tested will be processed in the same\n",
    "manner as during real-time use. Classifications will occur every 100 ms, at the frequency of real-time data throughput.\n",
    "During the post-processing step, a voting window looking at the most recent classification is used such that if a \n",
    "certain number of classifications (votes) in this window are 'grasp', then a click will be produced. Additionally, a \n",
    "lock-out period of 1 s will be applied immediately after each click so that to ensure that more than one click is not\n",
    "generated per attempted grasp.\n",
    "\n",
    "These clicks are then saved in an xarray and will then be used to assess the simulated performance of the model in the\n",
    "speller_analysis_simulated_click_detections.ipynb script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7079377-94ff-4c59-9ae9-1e535ea5510a",
   "metadata": {},
   "source": [
    "# IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0574fa2-0b83-4e37-a413-1d0e6887575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 16:03:29.314522: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-03-25 16:03:29.314556: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Please check to ensure that all of the libraries imported in functions_model_training_visual_labels.py are installed\n",
    "# in your environment or in the same file pathway. \n",
    "import functions_speller_playback\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aaec062-e562-4998-8da6-711f861de176",
   "metadata": {},
   "source": [
    "# SAVING A BACKUP OF THIS SCRIPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9481c2c2-4a1a-4fd9-8fbf-726fa7ff6456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mnt/shared/danprocessing/BACKUP/Projects/PseudoOnlineTests_for_RTCoG/Scripts/SpellerAnalysis/speller_playback.ipynb'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the original and target file directories.\n",
    "original = r'/home/dan/Projects/PseudoOnlineTests_for_RTCoG/Scripts/Recent/SpellerAnalysis/speller_playback.ipynb'\n",
    "target   = r'/mnt/shared/danprocessing/BACKUP/Projects/PseudoOnlineTests_for_RTCoG/Scripts/SpellerAnalysis/speller_playback.ipynb'\n",
    "\n",
    "# Saving.\n",
    "shutil.copyfile(original, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e573be2-9b70-4eed-af5f-6f3d6500ac6a",
   "metadata": {},
   "source": [
    "# INPUTTING PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85dcbb07-2eb8-4650-88fc-29cf5a99e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Please input the parameters below.\n",
    "\"\"\"\n",
    "\n",
    "# EXPERIMENTER INPUTS:\n",
    "block_id          = 'Block1'\n",
    "calib_name        = 'Calibration_S01'\n",
    "date              = '2023_01_06'\n",
    "dir_intermediates = '/mnt/shared/danprocessing/Projects/PseudoOnlineTests_for_RTCoG/Intermediates/'\n",
    "dir_model         = '/mnt/shared/danprocessing/Projects/PseudoOnlineTests_for_RTCoG/ClickModels'\n",
    "exper_name        = 'Speller_Adjusted_Block1' #'Speller_Adjusted_Block1'\n",
    "file_extension    = 'mat'\n",
    "model_config      = 'TestModel' \n",
    "patient_id        = 'CC01'\n",
    "\n",
    "\"\"\"\n",
    "INPUT VARIABLES:\n",
    "block_id:          [string]; Block number of the task.\n",
    "calib_name:        [string]; Name of the calibration task used to standardize the data.\n",
    "date:              [string]; Date on which the task was run. Format: YYYY_MM_DD.\n",
    "dir_intermediates: [string]; Intermediates directory where relevant information is stored.\n",
    "dir_model:         [string]; Directory where the model configuration and calibration information are stored.\n",
    "exper_name:        [string]; Name of the experimental task that was run.\n",
    "file_extension:    [string (hdf5/mat)]; The data file extension to be used.\n",
    "model_config:      [string]; Name of the model configuration.\n",
    "patient_id:        [string]; Patient PYyyNnn ID or CCXX ID.\n",
    "\"\"\";\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3688f2-0632-4f35-b24d-9e4482a67b0b",
   "metadata": {},
   "source": [
    "# UPLOADING MODEL AND MODEL PAREMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676a2447-ef77-4f51-b97e-2f983ea1804a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PACKET SIZE:  100  ms\n",
      "BUFFER SIZE:  256  ms\n",
      "CAR:  False\n",
      "CHANNELS INCLUDED:  ['chan52', 'chan49', 'chan50', 'chan61', 'chan51', 'chan57', 'chan59', 'chan56', 'chan62', 'chan35', 'chan60', 'chan44', 'chan54', 'chan39', 'chan55', 'chan48', 'chan64', 'chan33', 'chan58', 'chan47', 'chan63', 'chan34', 'chan42', 'chan46', 'chan53', 'chan41', 'chan37', 'chan40', 'chan36', 'chan45', 'chan43', 'chan38', 'chan89', 'chan66', 'chan95', 'chan77', 'chan96', 'chan76', 'chan71', 'chan94', 'chan70', 'chan78', 'chan73', 'chan84', 'chan67', 'chan86', 'chan72', 'chan79', 'chan74', 'chan85', 'chan65', 'chan68', 'chan92', 'chan90', 'chan87', 'chan91', 'chan75', 'chan93', 'chan80', 'chan83', 'chan82', 'chan81', 'chan88', 'chan69', 'chan121', 'chan122', 'chan114', 'chan120', 'chan119', 'chan113', 'chan111', 'chan116', 'chan126', 'chan117', 'chan112', 'chan105', 'chan107', 'chan118', 'chan104', 'chan115', 'chan101', 'chan125', 'chan109', 'chan99', 'chan98', 'chan97', 'chan102', 'chan100', 'chan108', 'chan128', 'chan103', 'chan127', 'chan106', 'chan124', 'chan110', 'chan123', 'chan19', 'chan18', 'chan17', 'chan24', 'chan21', 'chan23', 'chan22', 'chan30', 'chan20', 'chan25', 'chan28', 'chan27', 'chan29', 'chan31', 'chan32', 'chan6', 'chan26', 'chan14', 'chan13', 'chan15', 'chan12', 'chan16', 'chan7', 'chan4', 'chan9', 'chan3', 'chan5', 'chan2', 'chan8', 'chan1', 'chan10', 'chan11']\n",
      "TIME HISTORY:  1000  ms\n",
      "MODEL PATH:  /mnt/shared/danprocessing/Projects/PseudoOnlineTests_for_RTCoG/ClickModels/TestModel/Model_Info/Model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-25 16:03:30.986617: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-03-25 16:03:30.986653: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-03-25 16:03:30.986672: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (zappa): /proc/driver/nvidia/version does not exist\n",
      "2024-03-25 16:03:30.986872: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL:  <keras.engine.sequential.Sequential object at 0x7f2209df05b0>\n",
      "MODEL CLASSES:  ['rest', 'grasp']\n",
      "MODEL TYPE:  LSTM\n",
      "F-BAND MAX VALS:  [170] Hz\n",
      "F-BAND MIN VALS:  [110] Hz\n",
      "SAMPLING RATE:    1000 Sa/s\n",
      "SPECTRAL SHIFT:   100 ms\n",
      "SPECTRAL WINDOW:  256 ms\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Uploading all calibration and model configuration parameters. \n",
    "\n",
    "INPUT VARIABLES:\n",
    "dir_model:    [string]; Directory where the model configuration and calibration information are stored.\n",
    "model_config: [string]; Name of the model configuration.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Extracting all parameters as global variables to the function_speller_playback.py script.\n",
    "functions_speller_playback.uploading_parameters(dir_model, model_config)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8b00c-30a1-4e4e-a86a-9bafaa310711",
   "metadata": {},
   "source": [
    "# IMPORTING ELECTRODE AND AUXILLIARY CHANNELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1984458-33fd-40ae-b950-3ed9a46ad095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG LABELS: \n",
      " ['chan52', 'chan49', 'chan50', 'chan61', 'chan51', 'chan57', 'chan59', 'chan56', 'chan62', 'chan35', 'chan60', 'chan44', 'chan54', 'chan39', 'chan55', 'chan48', 'chan64', 'chan33', 'chan58', 'chan47', 'chan63', 'chan34', 'chan42', 'chan46', 'chan53', 'chan41', 'chan37', 'chan40', 'chan36', 'chan45', 'chan43', 'chan38', 'chan89', 'chan66', 'chan95', 'chan77', 'chan96', 'chan76', 'chan71', 'chan94', 'chan70', 'chan78', 'chan73', 'chan84', 'chan67', 'chan86', 'chan72', 'chan79', 'chan74', 'chan85', 'chan65', 'chan68', 'chan92', 'chan90', 'chan87', 'chan91', 'chan75', 'chan93', 'chan80', 'chan83', 'chan82', 'chan81', 'chan88', 'chan69', 'chan121', 'chan122', 'chan114', 'chan120', 'chan119', 'chan113', 'chan111', 'chan116', 'chan126', 'chan117', 'chan112', 'chan105', 'chan107', 'chan118', 'chan104', 'chan115', 'chan101', 'chan125', 'chan109', 'chan99', 'chan98', 'chan97', 'chan102', 'chan100', 'chan108', 'chan128', 'chan103', 'chan127', 'chan106', 'chan124', 'chan110', 'chan123', 'chan19', 'chan18', 'chan17', 'chan24', 'chan21', 'chan23', 'chan22', 'chan30', 'chan20', 'chan25', 'chan28', 'chan27', 'chan29', 'chan31', 'chan32', 'chan6', 'chan26', 'chan14', 'chan13', 'chan15', 'chan12', 'chan16', 'chan7', 'chan4', 'chan9', 'chan3', 'chan5', 'chan2', 'chan8', 'chan1', 'chan10', 'chan11', 'ainp1', 'ainp2', 'ainp3']\n",
      "\n",
      "\n",
      "AUX LABELS: \n",
      " ['VideoGrasp', 'StimulusCode', 'ResultCode', 'Baseline', 'TrialStart', 'Response', 'ControlUp', 'ControlDown', 'ControlLeft', 'ControlRight', 'ControlClick', 'CursorUp', 'CursorDown', 'CursorLeft', 'CursorRight', 'CursorClick', 'CuePeriod', 'ResponsePeriod', 'cursorX', 'cursorY', 'textCaregiver', 'NSPSyncState', 'EyetrackerLeftEyeGazeX', 'EyetrackerLeftEyeGazeY', 'EyetrackerRightEyeGazeX', 'EyetrackerRightEyeGazeY', 'EyetrackerLeftEyePosX', 'EyetrackerLeftEyePosY', 'EyetrackerRightEyePosX', 'EyetrackerRightEyePosY', 'EyetrackerLeftPupilSize', 'EyetrackerRightPupilSize', 'EyetrackerLeftEyeDist', 'EyetrackerRightEyeDist', 'EyetrackerLeftEyeValidity', 'EyetrackerRightEyeValidity', 'EyetrackerStatesOK', 'EyetrackerTimeStamp', 'Recording', 'SourceTime', 'StimulusTime', 'Running', 'MovementOnset', 'MovementOffset']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "The eeglabels and auxlabels lists will be populated with eeg channel names and auxilliary channel\n",
    "names respectively. These lists are created differently based on whether the data is extracted from\n",
    "a .hdf5 file or a .mat file. The EEG and auxilliary information will be uploaded from the following\n",
    "pathway:\n",
    "\n",
    "'/mnt/shared/ecog/' + patient_id + '/' + file_extension + '/' + date + '/' + task + '_' + block_id + '.' + file_extension\n",
    "\n",
    "Feel free to modify the pathway in which these data are stored and the necessary experimenter inputs\n",
    "appropriately.\n",
    "\n",
    "INPUT VARIABLES:\n",
    "date:           [string]; Date on which the speller was run. Format: YYYY_MM_DD.\n",
    "exper_name:     [string]; Name of the experimental task that was run.\n",
    "file_extension: [string (hdf5/mat)]; The data file extension to be used.\n",
    "patient_id:     [string]; Patient PYyyNnn ID or CCXX ID.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "auxlabels: [array > strings (aux channel names)]: Auxilliary channels extracted from the .hdf5\n",
    "           or .mat file.\n",
    "eeglabels: [list > strings (eeg channel names)]: EEG channels extracted from the .hdf5 or .mat file.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Importing the eeg and auxilliary channel labels.\n",
    "auxlabels,\\\n",
    "eeglabels = functions_speller_playback.import_electrode_information(date, exper_name, file_extension, patient_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627114b7-2182-480c-b2da-fbf22b636ad4",
   "metadata": {},
   "source": [
    "# UPLOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f3607bd-a928-47cd-b51e-92ecab962c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "For the experimenter-input block of speller data, the signal, clicks, and sampling information\n",
    "are stored in a dictionary. The BCI2000 data will be uploaded from the following pathway:\n",
    "\n",
    "'/mnt/shared/ecog/' + patient_id + '/' + file_extension + '/' + date + '/' + task + '_' + block_id + '.' + file_extension\n",
    "\n",
    "Feel free to modify the pathway in which these data are stored and the necessary experimenter\n",
    "inputs appropriately.\n",
    "\"\"\"\n",
    "\n",
    "# EXPERIMENTER INPUTS:\n",
    "state_marker_calib = 'StimulusCode' # StimulusCode\n",
    "state_marker_click = 'ControlClick' # ControlClick, StimulusCode\n",
    "\n",
    "\"\"\"\n",
    "INPUT VARIABLES:\n",
    "calib_name:         [string]; Name of the calibration task used to standardize the data.\n",
    "date:               [string]; Date on which the task was run. Format: YYYY_MM_DD.\n",
    "eeglabels:          [list > strings (eeg channel names)]: EEG channels extracted from the .hdf5 or\n",
    "                    .mat file.\n",
    "exper_name:         [string]; Name of the experimental task that was run.\n",
    "file_extension:     [string (hdf5/mat)]; The data file extension to be used.\n",
    "patient_id:         [string]; Patient PYyyNnn ID or CCXX ID.\n",
    "state_marker_calib: [string]; The name of the state marker for extracting calibration task state\n",
    "                    values.\n",
    "state_marker_click: [string]; The name of the state marker the experimenter wishes to extract from\n",
    "                    the task data.\n",
    "\n",
    "GLOBAL PARAMETERS (in functions_speller_playback.py):\n",
    "sampling_rate: [int (samples/s)]; Sampling rate at which the data was recorded.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "data_calib_dict: [dict (Key: string (task ID); Values: dict (Key/Value pairs below))]; \n",
    "    signals:     [xarray (channels x time samples) > floats (units: microvolts)]; Array of raw time signals\n",
    "                 of the calibration task across all channels. Time samples are in units of seconds.\n",
    "    states:      [xarray (1 x time samples) > ints]; Array of states at each time sample of the calibration\n",
    "                 task. Time samples are in units of seconds.\n",
    "data_exper_dict: [dict (Key: string (task ID); Values: dict (Key/Value pairs below))]; \n",
    "    signals:     [xarray (channels x time samples) > floats (units: microvolts)]; Array of raw time signals\n",
    "                 of the experimental task across all channels. Time samples are in units of seconds.\n",
    "    states:      [xarray (1 x time samples) > ints]; Array of states at each time sample of the experimental\n",
    "                 task. Time samples are in units of seconds.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Uploading data.\n",
    "data_calib_dict = functions_speller_playback.data_upload(date, eeglabels, calib_name, file_extension,\\\n",
    "                                                         patient_id, state_marker_calib)\n",
    "data_exper_dict = functions_speller_playback.data_upload(date, eeglabels, exper_name, file_extension,\\\n",
    "                                                         patient_id, state_marker_click)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b5564-0070-4dd4-b1c7-bf4aafc5b758",
   "metadata": {},
   "source": [
    "# LOADING BLOCK START AND STOP TIMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "547cb001-8ce8-4032-ab03-95cf8b282a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start time (s):  31.667\n",
      "End time (s):  926.5\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Loading the true starting and stopping times for the current block. The starting and stop times are in:\n",
    "\n",
    "dir_intermediates + patient_id + '/Speller/BlocksStartAndStops/' + date + '/' + date + '_' + block_id +'_StartStop.txt'\n",
    "\n",
    "Feel free to modify the pathway in which these starting and ending points are stored and the necessary\n",
    "experimenter inputs appropriately.\n",
    "\n",
    "INPUT VARIABLES:\n",
    "block_id:          [String (BlockX, where X is an int))]; Block ID of the task that was run.\n",
    "date:              [string (YYYY_MM_DD)]; Date on which the block was run.\n",
    "dir_intermediates: [string]; Intermediates directory where relevant information is stored.\n",
    "patient_id:        [string]; Patient ID PYyyNnn or CCxx format, where y, n, and x are integers.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "t_start: [float (units: s)]; True starting time of the block.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Loading the starting and stopping times for the block.\n",
    "t_start, _ = functions_speller_playback.load_start_stop_times(block_id, date, dir_intermediates, patient_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afffa47-5aef-4cf2-a006-a22f3768ed1b",
   "metadata": {},
   "source": [
    "# ADJUSTING THE TIME COORDINATES OF THE NON-CALIBRATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84022e73-8bb9-4322-8754-8aa4261683c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Adjusting the time coordinates of the signals and states xarrays such that the starting time is the true\n",
    "starting time of the block.\n",
    "\n",
    "INPUT VARIABLES:\n",
    "data_exper_dict: [dict (Key: string (task ID); Values: dict (Key/Value pairs below))]; \n",
    "    signals:     [xarray (channels x time samples) > floats (units: microvolts)]; Array of raw time signals\n",
    "                 of the experimental task across all channels. Time samples are in units of seconds.\n",
    "    states:      [xarray (1 x time samples) > ints]; Array of states at each time sample of the experimental\n",
    "                 task. Time samples are in units of seconds.\n",
    "t_start:         [float (units: s)]; True starting time of the block.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "data_exper_dict: Same as above, only the time coordinates of the signals and states xarrays have been \n",
    "                 adjusted so that the starting time is t_start.\n",
    "\"\"\"\n",
    "\n",
    "# Adjusting the time coordinates.\n",
    "data_exper_dict = functions_speller_playback.adjusting_time_coords_to_block_start(data_exper_dict, t_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6705caa9-6a8b-4716-bba6-9a16a636842e",
   "metadata": {},
   "source": [
    "# CONVERTING THE STATES INTO STRINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a1d6241-ed3d-4d13-a0d7-6c5f08ad93da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Converting the state array elements from integer to strings values using mapping dictionaries. \n",
    "\"\"\"\n",
    "# EXPERIMENTER INPUTS:\n",
    "state_map_calib = {0: 'calib_off', 1: 'calib_on'}\n",
    "state_map_exper = {0: 'no_click', 1: 'click'}\n",
    "\n",
    "\"\"\"\n",
    "INPUT VARIABLES:\n",
    "data_calib_dict:  [dict (Key: string (task ID); Values: dict (Key/Value pairs below))]; \n",
    "    signals:      [xarray (channels x time samples) > floats (units: microvolts)]; Array of raw time signals\n",
    "                  of the calibration task across all channels. Time samples are in units of seconds.\n",
    "    states:       [xarray (1 x time samples) > ints]; Array of states at each time sample of the calibration\n",
    "                  task. Time samples are in units of seconds.\n",
    "data_exper_dict:  [dict (Key: string (task ID); Values: dict (Key/Value pairs below))]; \n",
    "    signals:      [xarray (channels x time samples) > floats (units: microvolts)]; Array of raw time signals\n",
    "                  of the experimental task across all channels. Time samples are in units of seconds.\n",
    "    states:       [xarray (1 x time samples) > ints]; Array of states at each time sample of the experimental\n",
    "                  task. Time samples are in units of seconds.\n",
    "state_map_calib:  [dict (key: int; Value: strings)]; Mapping from the numerical values in the states array\n",
    "                  from the calibration period to corresponding string names.\n",
    "state_map_exper:  [dict (key: int; Value: strings)]; Mapping from the numerical values in the states array\n",
    "                  from the experimental task to corresponding string names.\n",
    "  \n",
    "OUTPUT VARIABLES:\n",
    "data_calib_dict: [dictionary (Key: string (task ID); Value: dictionary (Key/Value pairs below)];\n",
    "    signals:     Same as input.\n",
    "    states:      [xarray (1 x time samples) > strings ('calib_on'/'calib_off')]; Array of states at each time\n",
    "                 sample of the calibration task. Time samples are in units of seconds.\n",
    "data_exper_dict: [dictionary (Key: string (task ID); Value: dictionary (Key/Value pairs below)];\n",
    "    signals:     Same as input.\n",
    "    states:      [xarray (1 x time samples) > strings ('click'/'no_click')]; Array of states at each time\n",
    "                 sample of the experimental task. Time samples are in units of seconds.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Converting the integer state values to strings.\n",
    "data_calib_dict = functions_speller_playback.string_state_maker(data_calib_dict, state_map_calib)\n",
    "data_exper_dict = functions_speller_playback.string_state_maker(data_exper_dict, state_map_exper)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2bf565-934f-42a7-b85e-08ba34446cf7",
   "metadata": {},
   "source": [
    "# EXTRACTING ONLY RELEVANT CALIBRATION SIGNALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a18d7991-161e-46fc-8dc5-63d9d2d12899",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Only extracting the signals and states where the state equals the calibration state value.\n",
    "\"\"\"\n",
    "# EXPERIMENTER INPUTS:\n",
    "calib_state_rel = 'calib_on'\n",
    "\n",
    "\"\"\"               \n",
    "INPUT VARIABLES:\n",
    "calib_state_rel: [string]; The string state corresponding to the time samples from where to extract the \n",
    "                 calibration data for computing baseline statistics.\n",
    "data_calib_dict: [dict (Key: string (task ID); Values: xarrays (below))]; \n",
    "    signals:     [xarray (channels x time samples) > floats (units: microvolts)]; Array of raw time signals\n",
    "                 of the calibration task across all channels. Time samples are in units of seconds.\n",
    "    states:      [xarray (1 x time samples) > ints]; Array of states at each time sample of the calibration \n",
    "                 task. Time samples are in  units of seconds.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "signals_calib: [xarray (channels, time samples) > floats (units: microvolts)]; Array of raw time signals\n",
    "               across all channels from only the time period with the appropriate calibration state. Time\n",
    "               samples are in units of seconds.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Extracting only the relevant calibration signals.\n",
    "signals_calib = functions_speller_playback.calib_signals_relevant(calib_state_rel, data_calib_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332dd8b9-e06b-4b98-b9b4-71faf2689033",
   "metadata": {},
   "source": [
    "# GENERATING SPECTROGRAMS FOR THE CALIBRATION SIGNALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80cc8db1-84e5-430d-a96d-fe23ff6599e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Computing the spectrograms of the calibration signals for each channel across all time. \n",
    "\n",
    "INPUT VARIABLES:\n",
    "signals_calib: [xarray (channels, time samples) > floats (units: microvolts)]; Array of raw time signals\n",
    "               across all channels from only the time period with the appropriate calibration state. Time\n",
    "               samples are in units of seconds.\n",
    "    \n",
    "GLOBAL PARAMETERS (in functions_speller_playback.py):\n",
    "sampling_rate: [int (samples/s)]; Sampling rate at which the data was recorded.\n",
    "sxx_shift:     [int (units: ms)]; Length of time by which sliding window (sxx_window) shifts along the time \n",
    "               domain.\n",
    "sxx_window:    [int (units: ms)]; Time length of the window that computes the frequency power.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "sxx_signals_calib: [xarray (channels, frequency bins, time samples) > floats (units: V^2/Hz)]; Spectral power\n",
    "                   of the raw signals for each channel. Time samples are in units of seconds.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Computing the spectrogram of the calibration signals.\n",
    "sxx_signals_calib = functions_speller_playback.spectrogram_generator(signals_calib)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81ecf95-50b9-4699-baa9-541d542dca3d",
   "metadata": {},
   "source": [
    "# COMPUTING THE BASELINE FOR THE CALIBRATION PERIOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8cc5660-4b6c-4fd9-a6b5-cbbaae473158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Computing the mean and standard deviation of the calibration signals for each channel and frequency bin across\n",
    "all time points.\n",
    "\n",
    "INPUT VARIABLES:\n",
    "sxx_signals_calib: [xarray (channels, frequency bins, time samples) > floats (units: V^2/Hz)]; Spectral power \n",
    "                   of the continuous voltage signals for each channel. Time samples are in units of seconds.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "calibration_sxx_mean   [xarray (channels, frequency bins) > floats (units: V^2/Hz)]; Calibration mean of each \n",
    "                       channel and frequency bin across time.\n",
    "calibration_sxx_stdev: [xarray (channels, frequency bins) > floats (units: V^2/Hz)]; Calibration standard deviation\n",
    "                       of each channel and frequency bin across time.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Computing the means and standard deviations.\n",
    "calibration_sxx_mean,\\\n",
    "calibration_sxx_stdev = functions_speller_playback.computing_calibration_stats(sxx_signals_calib)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "476b92ee-89d1-4be6-afe0-18a4e8f872e5",
   "metadata": {},
   "source": [
    "# SPLITTING RAW DATA INTO PACKETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c97b5576-8928-4960-8851-ec7b87fd631b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Creating a list of continuous voltage data packets which will be used to simulate packets of data throughput\n",
    "during real-time decoding. \n",
    "\n",
    "INPUT VARIABLES:\n",
    "data_exper_dict: [dictionary (Key: string (task ID); Value: dictionary (Key/Value pairs below)];\n",
    "    signals: [xarray (channels, time samples) > floats (units: microvolts)]; Array of continuous voltage time\n",
    "             signals of the experimental task from all channels. Time samples are in units of seconds.\n",
    "    states:  [xarray (1 x time samples) > strings ('click'/'no_click')]; Array of states at each time sample\n",
    "             of the experimental task. Time samples are in units of seconds.\n",
    "    \n",
    "GLOBAL PARAMETERS (functions_speller_playback.py):\n",
    "packet_size:   [float (units: ms)]; Temporal size of data-streamed package to decoder.\n",
    "sampling_rate: [int (samples/s)]; Sampling rate at which the data was recorded.\n",
    "    \n",
    "NECESSARY FUNCTIONS:\n",
    "index_advancer\n",
    "    \n",
    "OUTPUT VARIABLES:\n",
    "data_packets_dict: [dictionary (Keys/Value pairs below)];\n",
    "    states:        [list > strings]; List of state strings corresponding to each data packet. \n",
    "    signals:       [list > array (channels, time samples) > floats (units: uV)]; List of data packets where each\n",
    "                   packet contains continuous voltage data.\n",
    "    t_seconds:     [list > floats (units: s)]; List of time points for each packet.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Creating data packets.\n",
    "data_packets_dict = functions_speller_playback.creating_data_packets(data_exper_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b247f825-22da-484f-94ee-3af45f8f2dda",
   "metadata": {},
   "source": [
    "# CREATING FEATURE PACKETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1992e5-b376-4459-b868-5c388bb60065",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating across all signal packets::  48%|███████████████████████████████████▊                                       | 4274/8949 [03:03<03:18, 23.53it/s]"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "For each signal packet, computing the historical time features into a list.\n",
    "\n",
    "INPUT VARIABLES:\n",
    "calibration_sxx_mean   [xarray (channels, frequency bins) > floats (units: V^2/Hz)]; Calibration mean of each\n",
    "                       channel and frequency bin across time.\n",
    "calibration_sxx_stdev: [xarray (channels, frequency bins) > floats (units: V^2/Hz)]; Calibration standard deviation\n",
    "                       of each channel and frequency bin across time.\n",
    "data_packets_dict:     [dictionary (Keys/Value pairs below)];\n",
    "    states:            [list > strings]; List of state strings corresponding to each data packet. \n",
    "    signals:           [list > array (channels, time samples) > floats (units: uV)]; List of data packets where each\n",
    "                       packet contains continuous voltage data.\n",
    "    t_seconds:         [list > floats (units: s)]; List of time points for each packet.\n",
    "\n",
    "GLOBAL PARAMETERS:\n",
    "buffer_size:   [float (units: ms)]; Window length of raw signal used for computing spectrogram, which continuously\n",
    "               updates.\n",
    "sampling_rate: [int (samples/s)]; Sampling rate at which the data was recorded.\n",
    "t_history:     [float (unit: ms)]; Amount of feature time history.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "feature_packets: [dictionary (key: packet number; Values: below)]; \n",
    "    data:        [xarray (pc features, time samples) > floats (units: V^2/Hz)]; All historical time features for each \n",
    "                 packet.\n",
    "    time:        [float (units: s)]; Corresponding time for feature packet.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "feature_packets: [list > xarray (features x time samples) > floats (units: V^2/Hz)]; All historical time\n",
    "                 features for each packet.            \n",
    "packet_times: [list > floats (units: s)]; Corresponding time for each elapsed feature packet, and is updated\n",
    "              with the time of the current command.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Creating feature packets.\n",
    "feature_packets = functions_speller_playback.apply_preprocessing(calibration_sxx_mean, calibration_sxx_stdev,\\\n",
    "                                                                 data_packets_dict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5970c9f-13f6-4030-83a1-d3b6fca96dcf",
   "metadata": {},
   "source": [
    "# COMPUTING PACKET-WISE MODEL PROBABILITIES AND CLASSIFICATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44ab157-6daf-41f1-a69a-8c822357e1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Computing the model probabilities and classifications for each feature packet.\n",
    "\n",
    "INPUT VARIABLES:\n",
    "feature_packets: [dictionary (key: packet number; Values: below)]; \n",
    "    data:        [xarray (pc features, time samples) > floats (units: V^2/Hz)]; All historical time features for each \n",
    "                 packet.\n",
    "    time:        [float (units: s)]; Corresponding time for feature packet.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "model_outputs: [dictionary (key: packet number; Values: below)]; Dictionary containing the model probabilities, model\n",
    "               classification, and corresponding time for each data packet.\n",
    "    class:     [list > strings]; Classification for each packet.\n",
    "    prob:      [array (1 x classes) > floats]; Per-packet model probabilities for each class.\n",
    "    time:      [float (units: s)]; Corresponding time for each set of model probabilities.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Computing the model outputs for each feature packet.\n",
    "model_outputs = functions_speller_playback.model_output_per_packet(feature_packets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be52042-29d4-47b4-b47e-d15d6a633741",
   "metadata": {},
   "source": [
    "# VISUALIZING CLASSIFICATION OUTPUTS FOR EACH PACKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a304a34-5a9f-42c6-b770-a13b2830f2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Extracting the per-packet values for each key in the model_outputs dictionary and then plotting\n",
    "the model probabilities and packet classifications at between the experimenter-input starting and\n",
    "ending packet times.\n",
    "\"\"\"\n",
    "# EXPERIMENTER INPUTS:\n",
    "t_visualization_start = 100\n",
    "t_visualization_end   = 300\n",
    "\n",
    "\"\"\"\n",
    "INPUT VARIABLES:\n",
    "model_outputs:         [dictionary (key: packet number; Values: below)]; Dictionary containing the\n",
    "                       model probabilities, model classification, and corresponding time for each \n",
    "                       data packet.\n",
    "    class:             [list > strings]; Classification for each packet.\n",
    "    prob:              [array (1 x classes) > floats]; Per-packet model probabilities for each class.\n",
    "    time:              [float (units: s)]; Corresponding time for each set of model probabilities.\n",
    "t_visualization_start: [float (units: ms)]; Starting visualization time point.\n",
    "t_visualization_end:   [float (units: ms)]; Ending visualization time point.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Visualizing the classification outputs.\n",
    "functions_speller_playback.visualizing_classification_outputs(model_outputs, t_visualization_start,\\\n",
    "                                                              t_visualization_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebca3fa-e8f0-4ead-8f83-911fd7228c9b",
   "metadata": {},
   "source": [
    "# SIMULATING PER-PACKET COMMANDS SENT TO USER INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d19b02-11a9-4431-aefb-6fd7ac9e10b4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Using the classification that occurs with each packet of data, the real-time output to the user-interface \n",
    "is simulated below. After each packet of data, the decoder must decide whether or not to issue a click\n",
    "command to the user-interface. This is determined by the total number of grasp (or any other non-rest class)\n",
    "classifications (votes) accumulating within the voting buffer, which exceeds a pre-specified voting threshold.\n",
    "In other words, if a voting buffer takes into account the most recent N classfications (n_votes) at any given\n",
    "time, there must be a minimum threshold (number) of grasp votes (n_voting_thr) accumulating within this window\n",
    "to issue a click command to the user interface. Additionally, a lockout period (t_lockout) is enforced such \n",
    "that multiple commands from the same attempted movement are not sent to the user-interface. This lockout \n",
    "period starts at the most recent 'click' command sent to user-interface and during this time, no further \n",
    "'click' commands are allowed to be sent, even if the voting threshold was surpassed.\n",
    "\"\"\"\n",
    "# EXPERIMENTER INPUTS:\n",
    "n_votes     = 7\n",
    "n_votes_thr = 7\n",
    "t_lockout   = 1000\n",
    "\n",
    "\"\"\"\n",
    "INPUT VARIABLES:\n",
    "model_outputs: [dictionary (key: packet number; Values: below)]; Dictionary containing the model \n",
    "               probabilities, model classification, and corresponding time for each data packet.\n",
    "    class:     [list > strings]; Classification for each packet.\n",
    "    prob:      [array (1 x classes) > floats]; Per-packet model probabilities for each class.\n",
    "    time:      [float (units: s)]; Corresponding time for each set of model probabilities.\n",
    "n_votes:       [int]; Number of most recent classifications to consider when voting on whether a click should\n",
    "               or should not be issued in real-time decoding simulation. For N number of votes, the voting \n",
    "               window corresponds to N*packet size (unitless * ms) worth of data. For example, 7 votes with a\n",
    "               packet size of 100 ms corresponds to 700 ms of worth of data being considered in the voting\n",
    "               window.\n",
    "n_votes_thr:   [int]; Number of grasp votes which must accumulate within the most recent n_votes classifications\n",
    "               to issue a click command.\n",
    "t_lockout:     [float (units: ms)]; The minimum amount of time which must elapse after the most recent 'click'\n",
    "               command was issued, such that another 'click' command may be issued.\n",
    "\n",
    "GLOBAL PARAMETERS (in functions_speller_playback.py):\n",
    "packet_size: [float (units: ms)]; Temporal size of data-streamed packet to decoder.\n",
    "\n",
    "NECESSARY FUNCTIONS:\n",
    "command_from_voting_buffer\n",
    "sending_command\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "commands:    [dictionary (key: packet number; Values: below)]; Dictionary containing the per-packet commands\n",
    "             and corresponding times.\n",
    "    command: [string]; Command for each packet.\n",
    "    time:    [float (units: s)]; Correpsonding time for each command.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Computing the per-packet commands and timestamps for each packet.\n",
    "commands = functions_speller_playback.commands_per_packet_simulation(n_votes, n_votes_thr,\\\n",
    "                                                                     model_outputs, t_lockout)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1d66a4-08a3-45fd-82c9-e4aa86482c01",
   "metadata": {},
   "source": [
    "# UPSAMPLING THE LISTS OF COMMANDS AND PACKET TIMES TO BCI2000 RESOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd49542-71e0-4154-8105-27672efb6c26",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Upsampling the commands to match the sampling rate of BCI2000. This is because during a real-time session, \n",
    "command states are saved at the BCI2000 sampling rate resolution, and the analysis pipeline that will be used\n",
    "(speller_analysis_simulated_click_detections.ipynb) to compute the performance metrics of this simulation \n",
    "assumes the corresponding time resolution. \n",
    "\n",
    "INPUT VARIABLES:\n",
    "commands:    [dictionary (key: packet number; Values: below)]; Dictionary containing the per-packet commands\n",
    "             and corresponding times.\n",
    "    command: [string]; Command for each packet.\n",
    "    time:    [float (units: s)]; Correpsonding time for each command.\n",
    "t_start:     [float (units: s)]; True starting time of the block.\n",
    "\n",
    "GLOBAL PARAMETERS (in functions_speller_playback.py):\n",
    "sampling_rate: [int (samples/s)]; Sampling rate at which the data was recorded.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "bci2k_times:    [array > floats (units: ms)]; Time array at the sampling rate of BCI2000 which is bounded by\n",
    "                the final packet time.\n",
    "commands_bci2k: [list > strings ('nothing'/'click')]; Upsampled commands list at the BCI2000 sampling rate.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Upsampling the commands and corresponding times to BCI2000 resolution.\n",
    "bci2k_times,\\\n",
    "commands_bci2k = functions_speller_playback.upsampling_command_info_to_bci2000_resolution(commands, t_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f43ca1-daff-434e-806f-5e86f08c1cb0",
   "metadata": {},
   "source": [
    "# SHIFTING COMMANDS BY SIMULATED NETWORK DELAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8a2b8b-b7b3-42b8-9153-3dccf5576ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "In offline analysis of real-time use data, a networking delay between BCI2000 and the user-interface was observed,\n",
    "which caused the on-screen click to occur roughly 200 ms after it was detected by the decoder. This function \n",
    "simulates that networking delay by shifting all commands at BCI2000 sampling rate resolution further in time by \n",
    "200 ms.\n",
    "\"\"\"\n",
    "# EXPERIMENTER INPUTS:\n",
    "networking_delay = 200 # 200\n",
    "\n",
    "\"\"\"\n",
    "INPUT VARIABLES:\n",
    "commands_bci2k:   [list > strings ('nothing'/'click')]; Upsampled commands list at the BCI2000 sampling rate.\n",
    "networking_delay: [int (units: ms)]; Networking delay between the click being detected and being received by the\n",
    "                  user-interface.\n",
    "\n",
    "GLOBAL PARAMETERS (in functions_speller_playback.py):\n",
    "sampling_rate: [int (samples/s)]; Sampling rate at which the data was recorded.\n",
    "    \n",
    "OUTPUT VARIABLES:\n",
    "commands_bci2k: [list > strings ('nothing'/'click')]; Commands shifted by the number of samples corresponding to\n",
    "                the networking delay.    \n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Shifting the commands (at BCI2000 sampling rate resolution) by the networking delay.\n",
    "commands_bci2k = functions_speller_playback.shifting_commands_by_simulated_network_delay(commands_bci2k, networking_delay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f234027-683d-4c95-9949-6718f1347509",
   "metadata": {},
   "source": [
    "# VISUALIZING SINGLE PER-PACKET COMMANDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95e3ef-0ade-47c6-8bcf-5977a8d0fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Visualizing the commands for each packet between the experimneter-defined window.\n",
    "\n",
    "INPUT VARIABLES:\n",
    "bci2k_times:           [array > floats (units: ms)]; Time array at the sampling rate of BCI2000 which is \n",
    "                       bounded by the final packet time.\n",
    "commands_bci2k:        [list > strings ('nothing'/'click')]; Commands shifted by the number of samples \n",
    "                       corresponding to the networking delay.  \n",
    "t_visualization_start: [float (units: ms)]; Starting visualization time point.\n",
    "t_visualization_end:   [float (units: ms)]; Ending visualization time point.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Visualizing the command outputs.\n",
    "functions_speller_playback.visualizing_commands_outputs(bci2k_times, commands_bci2k, t_visualization_start,\\\n",
    "                                                        t_visualization_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be78ed44-5a95-4900-8c0f-e25df85b7105",
   "metadata": {},
   "source": [
    "# SIMULATING CLICK DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1a171-02a6-41ed-8aa4-52b613dcf861",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "A list of 'click' or 'nothing' commands will be created at each time sample, where after each 'click' is \n",
    "detected, it lasts for the number of samples corresponding to the click duration. This simulates how long the\n",
    "click appears on the user-interface.\n",
    "\"\"\"\n",
    "# EXPERIMENTER INPUTS:\n",
    "click_duration = 1000\n",
    "\n",
    "\"\"\"\n",
    "NPUT VARIABLES:\n",
    "click_duration: [int (units: ms)]; Duration of how long each click lasts.\n",
    "commands_bci2k: [list > strings ('nothing'/'click')]; Commands shifted by the number of samples corresponding to\n",
    "                the networking delay.    \n",
    "t_start:        [float (units: s)]; True starting time of the block.\n",
    "\n",
    "GLOBAL PARAMETERS (in functions_speller_playback.py):\n",
    "sampling_rate: [int (samples/s)]; Sampling rate at which the data was recorded.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "click_highlights_bci2k: [xarray > strings (click/no-click)]; For each time sample (at the resolution of the \n",
    "                        BCI2000 sampling rate), there exists a click or no-click entry. The time dimension\n",
    "                        of the xarray is in units of seconds.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Genrating the click highlights list.\n",
    "click_highlights_bci2k = functions_speller_playback.simulating_click_duration(click_duration, commands_bci2k,\\\n",
    "                                                                              t_start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ae8c3b-1596-4489-8707-292a6c7bd66a",
   "metadata": {},
   "source": [
    "# DOWNSAMPLING THE CLICK HIGHLIGHTS TO VIDEO FPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4deafd-a6cd-4c91-bdd0-0c17dc1310bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Downsampling the click highlights list to the video FPS resolution.\n",
    "\"\"\"\n",
    "# EXPERIMENTER INPUTS:\n",
    "fps = 30\n",
    "if date == '2023_01_10' or date == '2023_01_12':\n",
    "    fps = 60\n",
    "\n",
    "\"\"\"\n",
    "INPUT VARIABLES:\n",
    "click_highlights_bci2k: [xarray > strings (click/no-click)]; For each time sample (at the resolution of the \n",
    "                        BCI2000 sampling rate), there exists a click or no-click entry. The time dimension\n",
    "                        of the xarray is in units of seconds.\n",
    "fps:                    [int]; Frames per second of click highlights array simulation from video feed.\n",
    "t_start:                [float (units: s)]; True starting time of the block.\n",
    "\n",
    "GLOBAL PARAMETERS (in functions_speller_playback.py):\n",
    "sampling_rate: [int (samples/s)]; Sampling rate at which the data was recorded.\n",
    "\n",
    "OUTPUT VARIABLES:\n",
    "click_highlights_video: [xarray > strings]; At the video resolution, there exists a click or no-click entry.\n",
    "                        Time dimension in units of seconds at video resolution.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Computing the click highlights array and corresponding time array at video FPS resolution.\n",
    "click_highlights_video = functions_speller_playback.downsample_to_video_fps(click_highlights_bci2k, fps, t_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ded8dd-795b-4408-9482-22df015e856b",
   "metadata": {},
   "outputs": [],
   "source": [
    "click_highlights_video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bdb78b-9ce6-4641-96ec-f4fea1bf71e2",
   "metadata": {},
   "source": [
    "# VISUALIZING CLICKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31472fea-822a-4048-a412-c2afe0e0694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Visualizing the clicks highlights between the experimneter-defined window.\n",
    "\n",
    "INPUT VARIABLES:\n",
    "click_highlights_video: [xarray > strings]; At the video resolution, there exists a click or no-click entry.\n",
    "                        Time dimension in units of seconds at video resolution.\n",
    "t_visualization_start:  [float (units: ms)]; Starting visualization time point.\n",
    "t_visualization_end:    [float (units: ms)]; Ending visualization time point.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION:\n",
    "\n",
    "# Visualizing the click highlights.\n",
    "functions_speller_playback.visualizing_click_highlights(click_highlights_video, t_visualization_start,\\\n",
    "                                                        t_visualization_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eebf23-247f-43fc-9f58-860cb455e66c",
   "metadata": {},
   "source": [
    "# SAVING CLICK HIGHLIGHTS AT VIDEO RESOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835261ac-1622-4380-892f-e0a4b37ab957",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DESCRIPTION:\n",
    "Saving the click highlights xarray to the following pathway:\n",
    "\n",
    "/mnt/shared/danprocessing/Projects/PseudoOnlineTests_for_RTCoG/Intermediates/CC01/Speller/ClickDetections/Simulated/'\n",
    "+ date + '/' + block_id + '/' + str(n_votes) +'_vote_window_' + str(n_votes_thr) + '_vote_thr' + '/' \n",
    "+ date + '_' + block_id + '_' + click_highlights_name + '.nc'\n",
    "\n",
    "Feel free to modify the pathway in which these data are stored and the necessary experimenter inputs appropriately.\n",
    "\"\"\"\n",
    "\n",
    "# EXPERIMENTER INPUTS:\n",
    "click_highlights_name = 'click_highlights_video'\n",
    "\n",
    "\"\"\"\n",
    "INPUT VARIABLES:\n",
    "block_id:               [string]; Block number of the task.\n",
    "click_highlights:       [xarray > strings ('click'/'nothing')]; The array of 'click' commands simulating for how long\n",
    "                        a button on the user-interface is highlighted.\n",
    "click_highlights_name:  [string]; Name of the xarray file which will hold the click highlights array.\n",
    "click_highlights_video: [xarray > strings]; At the video resolution, there exists a click or no-click entry.\n",
    "                        Time dimension in units of seconds at video resolution.\n",
    "date:                   [string]; Date on which the task was run. Format: YYYY_MM_DD. \n",
    "n_votes:                [int]; Number of most recent classifications to consider when voting on whether a \n",
    "                        click should or should not be issued in real-time decoding simulation. For N number of\n",
    "                        votes, the voting window corresponds to N*packet size (unitless * ms) worth of data.\n",
    "                        For example, 7 votes with a packet size of 100 ms corresponds to 700 ms of worth of \n",
    "                        data being considered in the voting window.\n",
    "n_votes_thr:            [int]; Number of grasp votes which must accumulate within the most recent n_votes\n",
    "                        classifications to issue a click command.\n",
    "\"\"\"\n",
    "\n",
    "# COMPUTATION.\n",
    "\n",
    "# Saving the click highlights.\n",
    "functions_speller_playback.saving_click_highlights(block_id, click_highlights_video, click_highlights_name, date,\\\n",
    "                                                   n_votes, n_votes_thr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8576cd2-aada-4e89-b134-746500d137a8",
   "metadata": {},
   "source": [
    "# COMPUTING THE CLICKS WITH DIFFERENT VOTING THRESHOLDS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e1eba-4380-47bb-bb75-6e58c4e28552",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_votes_thr = 6\n",
    "\n",
    "# SIMULATING PER-PACKET COMMANDS SENT TO THE USER-INTERFACE\n",
    "commands = functions_speller_playback.commands_per_packet_simulation(n_votes, n_votes_thr, model_outputs, t_lockout)\n",
    "\n",
    "# UPSAMPLING THE LISTS OF COMMANDS AND PACKET TIMES TO BCI2000 RESOLUTION\n",
    "bci2k_times, commands_bci2k = functions_speller_playback.upsampling_command_info_to_bci2000_resolution(commands, t_start)\n",
    "\n",
    "# SHIFTING COMMANDS BY SIMULATED NETWORK DELAY\n",
    "commands_bci2k = functions_speller_playback.shifting_commands_by_simulated_network_delay(commands_bci2k, networking_delay)\n",
    "\n",
    "# SIMULATING CLICK DURATION\n",
    "click_highlights_bci2k = functions_speller_playback.simulating_click_duration(click_duration, commands_bci2k, t_start)\n",
    "\n",
    "# DOWNSAMPLING TO VIDEO TIME RESOLUTION\n",
    "click_highlights_video = functions_speller_playback.downsample_to_video_fps(click_highlights_bci2k, fps, t_start)\n",
    "\n",
    "# VISUALIZING THE CLICK HIGHLIGHTS\n",
    "functions_speller_playback.visualizing_click_highlights(click_highlights_video, t_visualization_start, t_visualization_end)\n",
    "\n",
    "# SAVING CLICK HIGHLIGHTS\n",
    "functions_speller_playback.saving_click_highlights(block_id, click_highlights_video, click_highlights_name, date, n_votes, n_votes_thr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccaf59d-099c-4f22-9550-e8f02446d468",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_votes_thr = 5\n",
    "\n",
    "# SIMULATING PER-PACKET COMMANDS SENT TO THE USER-INTERFACE\n",
    "commands = functions_speller_playback.commands_per_packet_simulation(n_votes, n_votes_thr, model_outputs, t_lockout)\n",
    "\n",
    "# UPSAMPLING THE LISTS OF COMMANDS AND PACKET TIMES TO BCI2000 RESOLUTION\n",
    "bci2k_times, commands_bci2k = functions_speller_playback.upsampling_command_info_to_bci2000_resolution(commands, t_start)\n",
    "\n",
    "# SHIFTING COMMANDS BY SIMULATED NETWORK DELAY\n",
    "commands_bci2k = functions_speller_playback.shifting_commands_by_simulated_network_delay(commands_bci2k, networking_delay)\n",
    "\n",
    "# SIMULATING CLICK DURATION\n",
    "click_highlights_bci2k = functions_speller_playback.simulating_click_duration(click_duration, commands_bci2k, t_start)\n",
    "\n",
    "# DOWNSAMPLING TO VIDEO TIME RESOLUTION\n",
    "click_highlights_video = functions_speller_playback.downsample_to_video_fps(click_highlights_bci2k, fps, t_start)\n",
    "\n",
    "# VISUALIZING THE CLICK HIGHLIGHTS\n",
    "functions_speller_playback.visualizing_click_highlights(click_highlights_video, t_visualization_start, t_visualization_end)\n",
    "\n",
    "# SAVING CLICK HIGHLIGHTS\n",
    "functions_speller_playback.saving_click_highlights(block_id, click_highlights_video, click_highlights_name, date, n_votes, n_votes_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d20aaa7-af2d-4ec6-937f-d0b580b86f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_votes_thr = 4\n",
    "\n",
    "# SIMULATING PER-PACKET COMMANDS SENT TO THE USER-INTERFACE\n",
    "commands = functions_speller_playback.commands_per_packet_simulation(n_votes, n_votes_thr, model_outputs, t_lockout)\n",
    "\n",
    "# UPSAMPLING THE LISTS OF COMMANDS AND PACKET TIMES TO BCI2000 RESOLUTION\n",
    "bci2k_times, commands_bci2k = functions_speller_playback.upsampling_command_info_to_bci2000_resolution(commands, t_start)\n",
    "\n",
    "# SHIFTING COMMANDS BY SIMULATED NETWORK DELAY\n",
    "commands_bci2k = functions_speller_playback.shifting_commands_by_simulated_network_delay(commands_bci2k, networking_delay)\n",
    "\n",
    "# SIMULATING CLICK DURATION\n",
    "click_highlights_bci2k = functions_speller_playback.simulating_click_duration(click_duration, commands_bci2k, t_start)\n",
    "\n",
    "# DOWNSAMPLING TO VIDEO TIME RESOLUTION\n",
    "click_highlights_video = functions_speller_playback.downsample_to_video_fps(click_highlights_bci2k, fps, t_start)\n",
    "\n",
    "# VISUALIZING THE CLICK HIGHLIGHTS\n",
    "functions_speller_playback.visualizing_click_highlights(click_highlights_video, t_visualization_start, t_visualization_end)\n",
    "\n",
    "# SAVING CLICK HIGHLIGHTS\n",
    "functions_speller_playback.saving_click_highlights(block_id, click_highlights_video, click_highlights_name, date, n_votes, n_votes_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df30ce0b-0d56-4695-9b9a-c428d787147a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_votes_thr = 3\n",
    "\n",
    "# SIMULATING PER-PACKET COMMANDS SENT TO THE USER-INTERFACE\n",
    "commands = functions_speller_playback.commands_per_packet_simulation(n_votes, n_votes_thr, model_outputs, t_lockout)\n",
    "\n",
    "# UPSAMPLING THE LISTS OF COMMANDS AND PACKET TIMES TO BCI2000 RESOLUTION\n",
    "bci2k_times, commands_bci2k = functions_speller_playback.upsampling_command_info_to_bci2000_resolution(commands, t_start)\n",
    "\n",
    "# SHIFTING COMMANDS BY SIMULATED NETWORK DELAY\n",
    "commands_bci2k = functions_speller_playback.shifting_commands_by_simulated_network_delay(commands_bci2k, networking_delay)\n",
    "\n",
    "# SIMULATING CLICK DURATION\n",
    "click_highlights_bci2k = functions_speller_playback.simulating_click_duration(click_duration, commands_bci2k, t_start)\n",
    "\n",
    "# DOWNSAMPLING TO VIDEO TIME RESOLUTION\n",
    "click_highlights_video = functions_speller_playback.downsample_to_video_fps(click_highlights_bci2k, fps, t_start)\n",
    "\n",
    "# VISUALIZING THE CLICK HIGHLIGHTS\n",
    "functions_speller_playback.visualizing_click_highlights(click_highlights_video, t_visualization_start, t_visualization_end)\n",
    "\n",
    "# SAVING CLICK HIGHLIGHTS\n",
    "functions_speller_playback.saving_click_highlights(block_id, click_highlights_video, click_highlights_name, date, n_votes, n_votes_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2bc9d7-8a32-40f9-a3f0-2479e9285b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_votes_thr = 2\n",
    "\n",
    "# SIMULATING PER-PACKET COMMANDS SENT TO THE USER-INTERFACE\n",
    "commands = functions_speller_playback.commands_per_packet_simulation(n_votes, n_votes_thr, model_outputs, t_lockout)\n",
    "\n",
    "# UPSAMPLING THE LISTS OF COMMANDS AND PACKET TIMES TO BCI2000 RESOLUTION\n",
    "bci2k_times, commands_bci2k = functions_speller_playback.upsampling_command_info_to_bci2000_resolution(commands, t_start)\n",
    "\n",
    "# SHIFTING COMMANDS BY SIMULATED NETWORK DELAY\n",
    "commands_bci2k = functions_speller_playback.shifting_commands_by_simulated_network_delay(commands_bci2k, networking_delay)\n",
    "\n",
    "# SIMULATING CLICK DURATION\n",
    "click_highlights_bci2k = functions_speller_playback.simulating_click_duration(click_duration, commands_bci2k, t_start)\n",
    "\n",
    "# DOWNSAMPLING TO VIDEO TIME RESOLUTION\n",
    "click_highlights_video = functions_speller_playback.downsample_to_video_fps(click_highlights_bci2k, fps, t_start)\n",
    "\n",
    "# VISUALIZING THE CLICK HIGHLIGHTS\n",
    "functions_speller_playback.visualizing_click_highlights(click_highlights_video, t_visualization_start, t_visualization_end)\n",
    "\n",
    "# SAVING CLICK HIGHLIGHTS\n",
    "functions_speller_playback.saving_click_highlights(block_id, click_highlights_video, click_highlights_name, date, n_votes, n_votes_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8220922-747d-443c-b1bf-d0fcd9558873",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_votes_thr = 1\n",
    "\n",
    "# SIMULATING PER-PACKET COMMANDS SENT TO THE USER-INTERFACE\n",
    "commands = functions_speller_playback.commands_per_packet_simulation(n_votes, n_votes_thr, model_outputs, t_lockout)\n",
    "\n",
    "# UPSAMPLING THE LISTS OF COMMANDS AND PACKET TIMES TO BCI2000 RESOLUTION\n",
    "bci2k_times, commands_bci2k = functions_speller_playback.upsampling_command_info_to_bci2000_resolution(commands, t_start)\n",
    "\n",
    "# SHIFTING COMMANDS BY SIMULATED NETWORK DELAY\n",
    "commands_bci2k = functions_speller_playback.shifting_commands_by_simulated_network_delay(commands_bci2k, networking_delay)\n",
    "\n",
    "# SIMULATING CLICK DURATION\n",
    "click_highlights_bci2k = functions_speller_playback.simulating_click_duration(click_duration, commands_bci2k, t_start)\n",
    "\n",
    "# DOWNSAMPLING TO VIDEO TIME RESOLUTION\n",
    "click_highlights_video = functions_speller_playback.downsample_to_video_fps(click_highlights_bci2k, fps, t_start)\n",
    "\n",
    "# VISUALIZING THE CLICK HIGHLIGHTS\n",
    "functions_speller_playback.visualizing_click_highlights(click_highlights_video, t_visualization_start, t_visualization_end)\n",
    "\n",
    "# SAVING CLICK HIGHLIGHTS\n",
    "functions_speller_playback.saving_click_highlights(block_id, click_highlights_video, click_highlights_name, date, n_votes, n_votes_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7396031-cfa0-4060-8c4e-2f0fea16a47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b1e77a-75ae-43c4-8938-6f2db1c7d92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "block_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9915de5f-6cb7-4a31-b64d-61d5cc6add54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de80377-fe21-409f-b185-b23653d30373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ded30-4db2-4ff4-be7a-c6bf26e8c9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37737474-bedf-43ec-ae59-7e8304706b50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe67293-ea68-4965-a550-b33824359544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4960574-e8f1-4f1c-9adf-3818586a2239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9f6fb8-aac9-4831-b3fe-fc6cc4bce080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3102bc68-228b-4146-97b5-95ad38277007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ClickDetectorEnv)",
   "language": "python",
   "name": "clickdetectorenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
